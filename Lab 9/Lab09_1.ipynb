{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce92a064-56c1-4f9b-a717-82b4189a681b",
   "metadata": {},
   "source": [
    "# A simple MNIst Digits classification using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34099816-94e2-4c69-83d6-4d855c68a1af",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'equal_valued' from 'sympy.core.numbers' (C:\\Anaconda3\\lib\\site-packages\\sympy\\core\\numbers.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransforms\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torchvision\\__init__.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Don't re-order these, we need to load the _C extension (done when importing\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# .extensions) before entering _meta_registrations.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torchvision\\models\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malexnet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdensenet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mefficientnet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torchvision\\models\\convnext.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn, Tensor\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Conv2dNormActivation, Permute\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstochastic_depth\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StochasticDepth\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_presets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ImageClassification\n",
      "File \u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torchvision\\ops\\__init__.py:23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgiou_loss\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m generalized_box_iou_loss\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Conv2dNormActivation, Conv3dNormActivation, FrozenBatchNorm2d, MLP, Permute, SqueezeExcitation\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpoolers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultiScaleRoIAlign\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mps_roi_align\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ps_roi_align, PSRoIAlign\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mps_roi_pool\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ps_roi_pool, PSRoIPool\n",
      "File \u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torchvision\\ops\\poolers.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mboxes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m box_area\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _log_api_usage_once\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mroi_align\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m roi_align\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# copying result_idx_in_level to a specific index in result[]\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# is not supported by ONNX tracing yet.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# _onnx_merge_levels() is an implementation supported by ONNX\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# that merges the levels to the right indices\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39munused\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_onnx_merge_levels\u001b[39m(levels: Tensor, unmerged_results: List[Tensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n",
      "File \u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torchvision\\ops\\roi_align.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn, Tensor\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_compile_supported\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mannotations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BroadcastingList2\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _pair\n",
      "File \u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\_dynamo\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_frame, eval_frame, resume_execution\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "File \u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py:31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mguards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GlobalStateGuard\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_compile_pg\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CompileTimeInstructionCounter\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compile_context, CompileContext, CompileId, tracing\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_logging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m structured\n",
      "File \u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\_dynamo\\utils.py:62\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inductor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minductor_config\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_shapes\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pytree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpytree\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fx\n",
      "File \u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\fx\\experimental\\symbolic_shapes.py:65\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ShapeGuard, Source, TracingContext\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_python_dispatch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_traceable_wrapper_subclass\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sympy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     66\u001b[0m     Application, FloorDiv, Mod, PythonMod, IsNonOverlappingAndDenseIndicator, CleanDiv, FloorToInt, CeilToInt\n\u001b[0;32m     67\u001b[0m )\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sympy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msolve\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m try_solve\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sympy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumbers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m int_oo\n",
      "File \u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\utils\\_sympy\\functions.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msympy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunction\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Application\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msympy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _torf, fuzzy_and, fuzzy_or\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msympy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumbers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m equal_valued\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msympy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moperations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LatticeOp, ShortCircuit\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msympy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msorting\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ordered\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'equal_valued' from 'sympy.core.numbers' (C:\\Anaconda3\\lib\\site-packages\\sympy\\core\\numbers.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942d69f9-1ff0-4a3d-9c51-3f5257ccdb46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0331c0ca-7fe6-43f7-a51d-d98bd439681b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pytorch utility imports\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "#neural net imports\n",
    "import torch.nn as nn, torch.nn.functional as F, torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "#import external libraries\n",
    "import pandas as pd,numpy as np,matplotlib.pyplot as plt, os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d56f8b8-04e0-42d7-b649-3caac6635f50",
   "metadata": {},
   "source": [
    "### Set device to GPU or CPU based on availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d19401c2-35fc-4742-b47f-9c99026cb8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ace51a-639e-47ca-9385-f8412b43c0d4",
   "metadata": {},
   "source": [
    "### Loading MNIST data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d8a6a87-344e-49b0-a5cd-dfc66dee11a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "input_folder_path = \"MNIST_data/\"\n",
    "#The CSV contains a flat file of images,\n",
    "#i.e. each 28*28 image is flattened into a row of 784 colums\n",
    "#(1 column represents a pixel value)\n",
    "#For CNN, we would need to reshape this to our desired shape\n",
    "train_df = pd.read_csv(input_folder_path+\"mnist_train.csv\")\n",
    "#First column is the target/label\n",
    "train_labels = train_df['label'].values\n",
    "#Pixels values start from the 2nd column\n",
    "train_images = (train_df.iloc[:,1:].values).astype('float32')\n",
    "#Training and Validation Split\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "                                             train_images\n",
    "                                             ,train_labels\n",
    "                                             ,random_state=2020\n",
    "                                             ,test_size=0.2)\n",
    "#Here we reshape the flat row into [#images,#Channels,#Width,#Height]\n",
    "#Given this a simple grayscale image, we will have just 1 channel\n",
    "train_images = train_images.reshape(train_images.shape[0],1,28, 28)\n",
    "val_images = val_images.reshape(val_images.shape[0],1,28, 28)\n",
    "#Also, let's plot few samples\n",
    "for i in range(0, 6):\n",
    "    plt.subplot(160 + (i+1))\n",
    "    plt.imshow(train_images[i].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "    plt.title(train_labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cb96d1-0047-44f6-bd25-749b9e49ecb7",
   "metadata": {},
   "source": [
    "### Covert Train Images from pandas/numpy to tensor and normalize the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "514717ef-68f8-4847-8ad4-348a32c611ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Labels Shape: torch.Size([48000])\n",
      "Train Images Shape: torch.Size([48000, 1, 28, 28])\n",
      "Validation Labels Shape: torch.Size([12000])\n",
      "Validation Images Shape: torch.Size([12000, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "#Covert Train Images from pandas/numpy to tensor and normalize the values\n",
    "train_images_tensor = torch.tensor(train_images)/255.0\n",
    "train_images_tensor = train_images_tensor.view(-1,1,28,28)\n",
    "train_labels_tensor = torch.tensor(train_labels)\n",
    "#Create a train TensorDataset\n",
    "train_tensor = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "#Covert Validation Images from pandas/numpy to tensor and normalize the values\n",
    "val_images_tensor = torch.tensor(val_images)/255.0\n",
    "val_images_tensor = val_images_tensor.view(-1,1,28,28)\n",
    "val_labels_tensor = torch.tensor(val_labels)\n",
    "#Create a Validation TensorDataset\n",
    "val_tensor = TensorDataset(val_images_tensor, val_labels_tensor)\n",
    "print(\"Train Labels Shape:\",train_labels_tensor.shape)\n",
    "print(\"Train Images Shape:\",train_images_tensor.shape)\n",
    "print(\"Validation Labels Shape:\",val_labels_tensor.shape)\n",
    "print(\"Validation Images Shape:\",val_images_tensor.shape)\n",
    "#Load Train and Validation TensorDatasets into the data generator for Training\n",
    "train_loader = DataLoader(train_tensor, batch_size=64\n",
    "                          , num_workers=2, shuffle=True)\n",
    "val_loader = DataLoader(val_tensor, batch_size=64, num_workers=2, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89488dfa-5d15-441f-8225-d63ed335ea65",
   "metadata": {},
   "source": [
    "## Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec038739-cec0-40cf-be85-e35073499ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define conv-net\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        #First unit of convolution\n",
    "        self.conv_unit_1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        #Second unit of convolution\n",
    "        self.conv_unit_2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        #Fully connected layers\n",
    "        self.fc1 = nn.Linear(7*7*32, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    #Connect the units\n",
    "    def forward(self, x):\n",
    "        out = self.conv_unit_1(x)\n",
    "        out = self.conv_unit_2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = F.log_softmax(out,dim=1)\n",
    "        return out\n",
    "#Define Functions for Model Evaluation and generating Predictions\n",
    "def make_predictions(data_loader):\n",
    "    #Explcitly set the model to eval mode\n",
    "    model.eval()\n",
    "    test_preds = torch.LongTensor()\n",
    "    actual = torch.LongTensor()\n",
    "    for data, target in data_loader:\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "        output = model(data)\n",
    "        #Predict output/Take the index of the output with max value\n",
    "        preds = output.cpu().data.max(1, keepdim=True)[1]\n",
    "        #Combine tensors from each batch\n",
    "        test_preds = torch.cat((test_preds, preds), dim=0)\n",
    "        actual  = torch.cat((actual,target),dim=0)\n",
    "    return actual,test_preds\n",
    "#Evalute model\n",
    "def evaluate(data_loader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    for data, target in data_loader:\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        output = model(data)\n",
    "        loss += F.cross_entropy(output, target, size_average=False).data.item()\n",
    "        predicted = output.data.max(1, keepdim=True)[1]\n",
    "        correct += (target.reshape(-1,1) == predicted.reshape(-1,1)).float().sum()\n",
    "    loss /= len(data_loader.dataset)\n",
    "    print('\\nAverage Val Loss: {:.4f}, Val Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
    "        loss, correct, len(data_loader.dataset),\n",
    "        100. * correct / len(data_loader.dataset)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d247a6dd-b539-4af5-85e6-2f311d8b916d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (conv_unit_1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_unit_2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=1568, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Create Model  instance\n",
    "model = ConvNet(10).to(device)\n",
    "#Define Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4187e24-08e0-4097-8def-23e284b0c643",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ecd7ce0-1ce7-4a3b-9a2a-1f0c43af0b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.0243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atif/opt/anaconda3/envs/tf/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Val Loss: 0.0718, Val Accuracy: 11722.0/12000 (97.683%)\n",
      "\n",
      "Epoch [2/5], Loss: 0.0139\n",
      "\n",
      "Average Val Loss: 0.0471, Val Accuracy: 11816.0/12000 (98.467%)\n",
      "\n",
      "Epoch [3/5], Loss: 0.1336\n",
      "\n",
      "Average Val Loss: 0.0572, Val Accuracy: 11795.0/12000 (98.292%)\n",
      "\n",
      "Epoch [4/5], Loss: 0.1206\n",
      "\n",
      "Average Val Loss: 0.0463, Val Accuracy: 11837.0/12000 (98.642%)\n",
      "\n",
      "Epoch [5/5], Loss: 0.0062\n",
      "\n",
      "Average Val Loss: 0.0472, Val Accuracy: 11842.0/12000 (98.683%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    #After each epoch print Train loss and validation loss + accuracy\n",
    "    print ('Epoch [{}/{}], Loss: {:.4f}' .format(epoch+1, num_epochs, loss.item()))\n",
    "    evaluate(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be939e5e-7a8b-4737-b6ea-c81a534a8e6a",
   "metadata": {},
   "source": [
    "### Predictions and accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dd43501-d1d0-4864-aae6-74e49d42bc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy- 98.68\n",
      "\n",
      " Confusion Matrix\n",
      " [[1135    1    2    1    0    3    1    0    3    2]\n",
      " [   1 1369    2    1    1    0    0    2    4    0]\n",
      " [   0    2 1170    3    2    0    1    2    3    1]\n",
      " [   1    1    4 1233    0    7    0    1    4    1]\n",
      " [   0    1    0    0 1188    0    1    0    0    1]\n",
      " [   0    0    0    1    2 1088    0    0    0    2]\n",
      " [   2    0    1    1    4    8 1129    0    3    0]\n",
      " [   0    7    2    0   10    1    0 1184    0   15]\n",
      " [   1    0    1    1    5    5    0    0 1150    3]\n",
      " [   0    0    0    0   12    6    0    2    3 1196]]\n"
     ]
    }
   ],
   "source": [
    "#Make Predictions on Validation Dataset\n",
    "actual, predicted = make_predictions(val_loader)\n",
    "actual,predicted = np.array(actual).reshape(-1,1),np.array(predicted).reshape(-1,1)\n",
    "print(\"Validation Accuracy-\",round(accuracy_score(actual,predicted),4)*100)\n",
    "print(\"\\n Confusion Matrix\\n\",confusion_matrix(actual,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64648193-a6d0-4cc4-9a13-dd36db5c346d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
